{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/summitgao/CAMixer/main/preclassify.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CIuFTRrdxwt",
        "outputId": "cdfe37c0-2048-4f5f-9352-43eb102d1c92"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-05 03:35:38--  https://raw.githubusercontent.com/summitgao/CAMixer/main/preclassify.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5808 (5.7K) [text/plain]\n",
            "Saving to: ‘preclassify.py’\n",
            "\n",
            "\rpreclassify.py        0%[                    ]       0  --.-KB/s               \rpreclassify.py      100%[===================>]   5.67K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-06-05 03:35:38 (48.1 MB/s) - ‘preclassify.py’ saved [5808/5808]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YKYmnGn_FsF9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import skimage\n",
        "from skimage import io, measure\n",
        "import random\n",
        "import scipy.io as sio\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "from preclassify import del2, srad, dicomp, FCM, hcluster\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import cv2\n",
        "from collections import  Counter\n",
        "\n",
        "\n",
        "\n",
        "im1_path  = '/content/ottawa_1.bmp'\n",
        "im2_path  = '/content/ottawa_2.bmp'\n",
        "imgt_path = '/content/ottawa_gt.bmp'\n",
        "\n",
        "# important parameter\n",
        "patch_size = 7"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def image_normalize(data):\n",
        "    import math\n",
        "    _mean = np.mean(data)\n",
        "    _std = np.std(data)\n",
        "    npixel = np.size(data) * 1.0\n",
        "    min_stddev = 1.0 / math.sqrt(npixel)\n",
        "    return (data - _mean) / max(_std, min_stddev)\n",
        "\n",
        "def image_padding(data,r):\n",
        "    if len(data.shape)==3:\n",
        "        data_new=np.lib.pad(data,((r,r),(r,r),(0,0)),'constant',constant_values=0)\n",
        "        return data_new\n",
        "    if len(data.shape)==2:\n",
        "        data_new=np.lib.pad(data,r,'constant',constant_values=0)\n",
        "        return data_new\n",
        "#生成自然数数组并打乱\n",
        "def arr(length):\n",
        "  arr=np.arange(length-1)\n",
        "  #print(arr)\n",
        "  random.shuffle(arr)\n",
        "  #print(arr)\n",
        "  return arr\n",
        "\n",
        "\n",
        "# 在每个像素周围提取 patch ，然后创建成符合 pytorch 处理的格式\n",
        "def createTrainingCubes(X, y, patch_size):\n",
        "    # 给 X 做 padding\n",
        "    margin = int((patch_size - 1) / 2)\n",
        "    zeroPaddedX = image_padding(X, margin)\n",
        "    # 把类别 uncertainty 的像素忽略\n",
        "    ele_num1 = np.sum(y==1)\n",
        "    ele_num2 = np.sum(y==2)\n",
        "    patchesData_1 = np.zeros( (ele_num1, patch_size, patch_size, X.shape[2]) )\n",
        "    patchesLabels_1 = np.zeros(ele_num1)\n",
        "\n",
        "    patchesData_2 = np.zeros((ele_num2, patch_size, patch_size, X.shape[2]))\n",
        "    patchesLabels_2 = np.zeros(ele_num2)\n",
        "\n",
        "    patchIndex_1 = 0\n",
        "    patchIndex_2 = 0\n",
        "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
        "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
        "            # remove uncertainty pixels\n",
        "            if y[r-margin, c-margin] == 1 :\n",
        "                patch_1 = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]\n",
        "                patchesData_1[patchIndex_1, :, :, :] = patch_1\n",
        "                patchesLabels_1[patchIndex_1] = y[r-margin, c-margin]\n",
        "                patchIndex_1 = patchIndex_1 + 1\n",
        "            elif y[r-margin, c-margin] == 2 :\n",
        "                patch_2 = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]\n",
        "                patchesData_2[patchIndex_2, :, :, :] = patch_2\n",
        "                patchesLabels_2[patchIndex_2] = y[r-margin, c-margin]\n",
        "                patchIndex_2 = patchIndex_2 + 1\n",
        "    patchesLabels_1 = patchesLabels_1-1\n",
        "    patchesLabels_2 = patchesLabels_2-1\n",
        "\n",
        "    #调用arr函数打乱数组\n",
        "    arr_1=arr(len(patchesData_1))\n",
        "    arr_2=arr(len(patchesData_2))\n",
        "\n",
        "    train_len=10000  #设置训练集样本数\n",
        "    pdata=np.zeros((train_len, patch_size, patch_size, X.shape[2]))\n",
        "    plabels = np.zeros(train_len)\n",
        "\n",
        "    for i in range(7000):\n",
        "      pdata[i,:,:,:]=patchesData_1[arr_1[i],:,:,:]\n",
        "      plabels[i]=patchesLabels_1[arr_1[i]]\n",
        "    for j in range(7000,train_len):\n",
        "      pdata[j,:,:,:]=patchesData_2[arr_2[j-7000],:,:,:]\n",
        "      plabels[j]=patchesLabels_2[arr_2[j-7000]]\n",
        "\n",
        "    return pdata, plabels\n",
        "\n",
        "\n",
        "def createTestingCubes(X, patch_size):\n",
        "    # 给 X 做 padding\n",
        "    margin = int((patch_size - 1) / 2)\n",
        "    zeroPaddedX = image_padding(X, margin)\n",
        "    patchesData = np.zeros( (X.shape[0]*X.shape[1], patch_size, patch_size, X.shape[2]) )\n",
        "    patchIndex = 0\n",
        "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
        "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
        "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]\n",
        "            patchesData[patchIndex, :, :, :] = patch\n",
        "            patchIndex = patchIndex + 1\n",
        "    return patchesData\n",
        "\n",
        "\n",
        "#  Inputs:  gtImg  = ground truth image\n",
        "#           tstImg = change map\n",
        "#  Outputs: FA  = False alarms\n",
        "#           MA  = Missed alarms\n",
        "#           OE  = Overall error\n",
        "#           PCC = Overall accuracy\n",
        "def evaluate(gtImg, tstImg):\n",
        "    gtImg[np.where(gtImg>128)] = 255\n",
        "    gtImg[np.where(gtImg<128)] = 0\n",
        "    tstImg[np.where(tstImg>128)] = 255\n",
        "    tstImg[np.where(tstImg<128)] = 0\n",
        "    [ylen, xlen] = gtImg.shape\n",
        "    FA = 0\n",
        "    MA = 0\n",
        "    label_0 = np.sum(gtImg==0)\n",
        "    label_1 = np.sum(gtImg==255)\n",
        "    print(label_0)\n",
        "    print(label_1)\n",
        "\n",
        "    for j in range(0,ylen):\n",
        "        for i in range(0,xlen):\n",
        "            if gtImg[j,i]==0 and tstImg[j,i]!=0 :\n",
        "                FA = FA+1\n",
        "            if gtImg[j,i]!=0 and tstImg[j,i]==0 :\n",
        "                MA = MA+1\n",
        "\n",
        "    OE = FA+MA\n",
        "    PCC = 1-OE/(ylen*xlen)\n",
        "    PRE=((label_1+FA-MA)*label_1+(label_0+MA-FA)*label_0)/((ylen*xlen)*(ylen*xlen))\n",
        "    KC=(PCC-PRE)/(1-PRE)\n",
        "    print(' Change detection results ==>')\n",
        "    print(' ... ... FP:  ', FA)\n",
        "    print(' ... ... FN:  ', MA)\n",
        "    print(' ... ... OE:  ', OE)\n",
        "    print(' ... ... PCC: ', format(PCC*100, '.2f'))\n",
        "    print(' ... ... KC: ', format(KC*100, '.2f'))\n",
        "\n",
        "\n",
        "def postprocess(res):\n",
        "    res_new = res\n",
        "    res = measure.label(res, connectivity=2)\n",
        "    num = res.max()\n",
        "    for i in range(1, num+1):\n",
        "        idy, idx = np.where(res==i)\n",
        "        if len(idy) <= 20:\n",
        "            res_new[idy, idx] = 0\n",
        "    return res_new"
      ],
      "metadata": {
        "id": "wstL2eDSGn4Y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read image, and then tranform to float32\n",
        "im1 = io.imread(im1_path)[:,:,0].astype(np.float32)\n",
        "im2 = io.imread(im2_path)[:,:,0].astype(np.float32)\n",
        "\n",
        "im_gt = io.imread(imgt_path)[:,:,0].astype(np.float32)\n",
        "\n",
        "im_di = dicomp(im1, im2)\n",
        "ylen, xlen = im_di.shape\n",
        "pix_vec = im_di.reshape([ylen*xlen, 1])\n",
        "\n",
        "\n",
        "# hiearchical FCM clustering\n",
        "# in the preclassification map,\n",
        "# pixels with high probability to be unchanged are labeled as 1\n",
        "# pixels with high probability to be changed are labeled as 2\n",
        "# pixels with uncertainty are labeled as 1.5\n",
        "preclassify_lab = hcluster(pix_vec, im_di)\n",
        "print('... ... hiearchical clustering finished !!!')\n",
        "\n",
        "\n",
        "mdata = np.zeros([im1.shape[0], im1.shape[1], 3], dtype=np.float32)\n",
        "mdata[:,:,0] = im1\n",
        "mdata[:,:,1] = im2\n",
        "mdata[:,:,2] = im_di\n",
        "mlabel = preclassify_lab\n",
        "\n",
        "x_train, y_train = createTrainingCubes(mdata, mlabel, patch_size)\n",
        "x_train = x_train.transpose(0, 3, 1, 2)\n",
        "print('... x train shape: ', x_train.shape)\n",
        "print('... y train shape: ', y_train.shape)\n",
        "\n",
        "\n",
        "x_test = createTestingCubes(mdata, patch_size)\n",
        "x_test = x_test.transpose(0, 3, 1, 2)\n",
        "print('... x test shape: ', x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUA1eku8HLwv",
        "outputId": "e1833b44-df92-4d53-cbd2-a036bb6c2ce8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "... ... hiearchical clustering finished !!!\n",
            "... x train shape:  (10000, 3, 7, 7)\n",
            "... y train shape:  (10000,)\n",
            "... x test shape:  (101500, 3, 7, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\" Training dataset\"\"\"\n",
        "class TrainDS(torch.utils.data.Dataset):\n",
        "    def __init__(self):\n",
        "        self.len = x_train.shape[0]\n",
        "        self.x_data = torch.FloatTensor(x_train)\n",
        "        self.y_data = torch.LongTensor(y_train)\n",
        "    def __getitem__(self, index):\n",
        "        # 根据索引返回数据和对应的标签\n",
        "\n",
        "        #x=torch.FloatTensor(data_rotate(self.x_data[index].cpu().numpy()))\n",
        "        #y=torch.FloatTensor(gasuss_noise(self.y_data[index]))\n",
        "        #x=torch.FloatTensor(datarotate(self.x_data[index]))\n",
        "        #return x,self.y_data[index]\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "    def __len__(self):\n",
        "        # 返回文件数据的数目\n",
        "        return self.len\n",
        "\n",
        "# 创建 trainloader 和 testloader\n",
        "trainset = TrainDS()\n",
        "train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size=128, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "gFgRP-39HTRQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MRC(nn.Module):\n",
        "    def __init__(self, inchannel):\n",
        "        super(MRC, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inchannel, 15, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(15)\n",
        "\n",
        "        self.conv2_1 = nn.Conv2d(5, 5, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.bn2_1 = nn.BatchNorm2d(5)\n",
        "\n",
        "        self.conv2_2 = nn.Conv2d(5, 5, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.bn2_2 = nn.BatchNorm2d(5)\n",
        "\n",
        "        self.conv2_3 = nn.Conv2d(5, 5, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.bn2_3 = nn.BatchNorm2d(5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ori_out = F.relu(self.bn1(self.conv1(x)))\n",
        "\n",
        "        shape=(x.shape[0], 5, 7, 7)\n",
        "\n",
        "        all_zero3_3=torch.zeros(size=shape).cuda()\n",
        "        all_zero1_3=torch.zeros(size=(x.shape[0], 5, 3, 7)).cuda()\n",
        "        all_zero3_1=torch.zeros(size=(x.shape[0], 5, 7, 3)).cuda()\n",
        "\n",
        "        all_zero3_3[:,:,:,:]=ori_out[:,0:5,:,:]\n",
        "        all_zero1_3[:,:,:,:]=ori_out[:,5:10,2:5,:]\n",
        "        all_zero3_1[:,:,:,:]=ori_out[:,10:15,:,2:5]\n",
        "\n",
        "        square=F.relu(self.bn2_1(self.conv2_1(all_zero3_3)))\n",
        "        horizontal=F.relu(self.bn2_2(self.conv2_2(all_zero1_3)))\n",
        "        vertical=F.relu(self.bn2_3(self.conv2_3(all_zero3_1)))\n",
        "        horizontal_final=torch.zeros(size=(x.shape[0], 5, 7, 7)).cuda()\n",
        "        vertical_final=torch.zeros(size=(x.shape[0], 5, 7, 7)).cuda()\n",
        "        horizontal_final[:,:,2:5,:]=horizontal[:,:,:,:]\n",
        "        vertical_final[:,:,:,2:5]=vertical[:,:,:,:]\n",
        "\n",
        "        glo = square + horizontal_final + vertical_final\n",
        "        #glo= F.relu(self.bn3(self.conv3(glo)))\n",
        "\n",
        "        return glo\n",
        "\n",
        "def DCT(x):\n",
        "      out=F.interpolate(x, size=(8,8), mode='bilinear', align_corners=True)\n",
        "      #print(out.shape)\n",
        "      #dct_out_1 =torch.Tensor([cv2.dct(x[i,0,:,:].detach().cpu().numpy()) \\\n",
        "      #                          for i in range(x.shape[0])])\n",
        "      dct_out_1 =torch.Tensor([cv2.dct(np.float32(out[i,0,:,:].detach().cpu().numpy())) \\\n",
        "                                for i in range(x.shape[0])])\n",
        "      dct_out_2 =torch.Tensor([cv2.dct(np.float32(out[i,1,:,:].detach().cpu().numpy())) \\\n",
        "                                for i in range(x.shape[0])])\n",
        "      dct_out_3 =torch.Tensor([cv2.dct(np.float32(out[i,2,:,:].detach().cpu().numpy())) \\\n",
        "                                for i in range(x.shape[0])])\n",
        "      dct_out=torch.zeros(size=(x.shape[0],3, 8, 8))\n",
        "      dct_out[:,0,:,:]=dct_out_1\n",
        "      dct_out[:,1,:,:]=dct_out_2\n",
        "      dct_out[:,2,:,:]=dct_out_3\n",
        "      dct_out=dct_out.cuda()#放回cuda\n",
        "      out=dct_out.view(x.shape[0], 3, 64)\n",
        "      #out=torch.cat((out,out),2)\n",
        "      out=F.glu(out,dim=-1)\n",
        "      dct_out=out.view(x.shape[0], 1, 96)\n",
        "      return dct_out\n"
      ],
      "metadata": {
        "id": "C8duKPWVHYeQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class DDNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DDNet, self).__init__()\n",
        "        self.mrc1=MRC(3)\n",
        "        self.mrc2=MRC(5)\n",
        "        self.mrc3=MRC(5)\n",
        "        self.mrc4=MRC(5)\n",
        "\n",
        "\n",
        "        self.linear1=nn.Linear(341, 10)\n",
        "        self.linear2=nn.Linear(10, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        m_1=self.mrc1(x)\n",
        "        m_2=self.mrc2(m_1)\n",
        "        m_3=self.mrc3(m_2)\n",
        "        m_4=self.mrc4(m_3)\n",
        "        #glo= F.relu(self.bn(self.conv(m_4)))\n",
        "        glo=m_4.view(x.shape[0], 1, 245)\n",
        "\n",
        "        dct_out=DCT(x)\n",
        "\n",
        "        out=torch.cat((glo,dct_out),2)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        #print(out.shape)\n",
        "        out_1 = self.linear1(out)\n",
        "        out = self.linear2(out_1)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "daFKJH5YHbZO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "istrain = True\n",
        "# 网络放到GPU上\n",
        "net =DDNet()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "net.train()\n",
        "\n",
        "# 开始训练\n",
        "total_loss = 0\n",
        "for epoch in range(50):\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "\n",
        "        inputs = inputs\n",
        "        labels = labels\n",
        "        # 优化器梯度归零\n",
        "        optimizer.zero_grad()\n",
        "        # 正向传播 +　反向传播 + 优化\n",
        "        outputs = net()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print('[Epoch: %d]  [loss avg: %.4f]  [current loss: %.4f]' %(epoch + 1, total_loss/(epoch+1), loss.item()))\n",
        "print('Finished Training')\n",
        "Q2"
      ],
      "metadata": {
        "id": "ZWiNl0JIHeAp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "ca6f319f-2ac1-4d6b-fe66-4ba4c3f036a6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "DDNet.forward() missing 1 required positional argument: 'x'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-96b75556a0a1>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# 正向传播 +　反向传播 + 优化\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: DDNet.forward() missing 1 required positional argument: 'x'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 逐像素预测类别\n",
        "istrain=False\n",
        "net.eval()\n",
        "outputs = np.zeros((ylen, xlen))\n",
        "glo_fin=torch.Tensor([]).cuda()\n",
        "dct_fin=torch.Tensor([]).cuda()\n",
        "for i in range(ylen):\n",
        "    for j in range(xlen):\n",
        "        if preclassify_lab[i, j] != 1.5 :\n",
        "            outputs[i, j] = preclassify_lab[i, j]\n",
        "        else:\n",
        "            img_patch = x_test[i*xlen+j, :, :, :]\n",
        "            img_patch = img_patch.reshape(1, img_patch.shape[0], img_patch.shape[1], img_patch.shape[2])\n",
        "            img_patch = torch.FloatTensor(img_patch).to(device)\n",
        "            prediction = net(img_patch)\n",
        "\n",
        "            prediction = np.argmax(prediction.detach().cpu().numpy(), axis=1)\n",
        "            outputs[i, j] = prediction+1\n",
        "    if (i+1) % 50 == 0:\n",
        "        print('... ... row', i+1, ' handling ... ...')\n",
        "\n",
        "outputs = outputs-1\n",
        "\n",
        "plt.imshow(outputs, 'gray')\n",
        "\n",
        "\n",
        "res = outputs*255\n",
        "res = postprocess(res)\n",
        "evaluate(im_gt, res)\n",
        "plt.imshow(res, 'gray')"
      ],
      "metadata": {
        "id": "m8hlB-SRHg6l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "b51ad6a5-bafc-4e62-aff9-c408526f7f99"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-9891f0d912be>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mylen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mglo_fin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdct_fin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mylen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0wmevoiTf6wb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}